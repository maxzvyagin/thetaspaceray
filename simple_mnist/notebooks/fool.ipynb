{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use the foolbox as the metric that we're minimizing for over hyperspace and see what kind of intersection we get between the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperspace import create_hyperspace\n",
    "from ray import tune\n",
    "import tensorflow as tf\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from ray.tune.suggest.skopt import SkOptSearch\n",
    "from skopt import Optimizer\n",
    "import ray\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import foolbox as fb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Tuning with Foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_tf_objective(config):\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dropout(config['dropout']),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=config['learning_rate'])\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    res = model.fit(x_train, y_train, epochs=config['epochs'], batch_size=config['batch_size'])\n",
    "    res_test = model.evaluate(x_test, y_test)\n",
    "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
    "    images, labels = fb.utils.samples(fmodel, dataset='mnist', batchsize=config['batch_size'])\n",
    "    clean_accuracy = fb.utils.accuracy(fmodel, images, labels)\n",
    "    attack = fb.attacks.L2AdditiveUniformNoiseAttack()\n",
    "    epsilons = [\n",
    "        0.0,\n",
    "        0.0002,\n",
    "        0.0005,\n",
    "        0.0008,\n",
    "        0.001,\n",
    "        0.0015,\n",
    "        0.002,\n",
    "        0.003,\n",
    "        0.01,\n",
    "        0.1,\n",
    "        0.3,\n",
    "        0.5,\n",
    "        1.0,\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "    print(success.numpy().astype(float).flatten())\n",
    "    robust_accuracy = 1 - success.numpy().astype(float).flatten().mean(axis=-1)\n",
    "    # res test[0] reports the loss from the evaluation, res_test[1] reports the accuracy\n",
    "    tune.report(robust_acc = robust_accuracy, test_loss = res_test[0])\n",
    "    \n",
    "    print(robust_accuracy)\n",
    "    return robust_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/mzvyagin/anaconda3/envs/resiliency/lib/python3.8/site-packages/hyperspace/space/skopt/space.py:173: UserWarning: Each hyperspace contains a single value.\n",
      "  warnings.warn(\"Each hyperspace contains a single value.\")\n"
     ]
    }
   ],
   "source": [
    "### Defining the hyperspace\n",
    "hyperparameters = [(0.00001, 0.1),  # learning_rate\n",
    "                   (0.2, 0.9),  # dropout\n",
    "                   (10, 100),  # epochs \n",
    "                   (10, 1000)]  # batch size\n",
    "space = create_hyperspace(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture tf_run_output\n",
    "\n",
    "### for each space in hyperspace, we want to search the space using ray tune\n",
    "results = []\n",
    "for section in tqdm(space):\n",
    "    # create a skopt gp minimize object\n",
    "    optimizer = Optimizer(section)\n",
    "    search_algo = SkOptSearch(optimizer, ['learning_rate', 'dropout', 'epochs', 'batch_size'],\n",
    "                              metric='robust_acc', mode='max')\n",
    "    # not using a gpu because running on local\n",
    "    analysis = tune.run(mnist_tf_objective, search_alg=search_algo, num_samples=20, local_dir=\"~/gaussian_noise_tf1\")\n",
    "    results.append(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f314054c7f0>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14fc040760>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f30e4267460>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14f6363f10>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f31ab046100>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14fc040b80>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14fc078a60>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f30e421dbb0>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14f67660a0>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14f52a1250>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14f674b6a0>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14ec5f4700>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f31aaddcc70>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14f52868b0>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14f5a30460>,\n",
       " <ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f14f5c43ac0>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tf_results = results[0].results_df\n",
    "for i in range(1, len(results)):\n",
    "    all_tf_results = all_tf_results.append(results[i].results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tf_results.to_csv(\"tf_fool_res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', \"w\") as f:\n",
    "    f.write(tf_run_output.stdout[-1100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
