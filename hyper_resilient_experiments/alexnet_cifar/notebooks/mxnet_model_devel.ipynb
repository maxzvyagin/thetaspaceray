{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is kind of a mess of different model configurations and debugging of mysterious MXNet errors that I still haven't figured out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import optimizer\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import HybridBlock\n",
    "from mxnet.gluon.data import vision\n",
    "from gluoncv.utils import makedirs, TrainingHistory\n",
    "import gluoncv\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AlexNet and CIFAR100 \n",
    "# Net\n",
    "\n",
    "class AlexNet(nn.Block):\n",
    "    r\"\"\"AlexNet model from the `\"One weird trick...\" `_ paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classes : int, default 1000\n",
    "        Number of classes for the output layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, classes=1000, **kwargs):\n",
    "        super(AlexNet, self).__init__(**kwargs)\n",
    "        self.blk = nn.Sequential()\n",
    "        self.blk.add(nn.Conv2D(64, kernel_size=11, strides=4,\n",
    "                                    padding=5, activation='relu', in_channels=3,layout=\"NHWC\"))\n",
    "        self.blk.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "        self.blk.add(nn.Conv2D(256, kernel_size=5, padding=2,\n",
    "                                    activation='relu',layout=\"NHWC\"))\n",
    "        self.blk.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "        self.blk.add(nn.Conv2D(384, kernel_size=3, padding=1,\n",
    "                                    activation='relu', layout=\"NHWC\"))\n",
    "        self.blk.add(nn.Conv2D(256, kernel_size=3, padding=1,\n",
    "                                    activation='relu', layout=\"NHWC\"))\n",
    "        self.blk.add(nn.Conv2D(256, kernel_size=3, padding=1,\n",
    "                                    activation='relu', layout=\"NHWC\"))\n",
    "        self.blk.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "        self.blk.add(nn.Flatten())\n",
    "        self.blk.add(nn.Dense(4096, activation='relu'))\n",
    "        self.blk.add(nn.Dropout(0.5))\n",
    "        self.blk.add(nn.Dense(4096, activation='relu'))\n",
    "        self.blk.add(nn.Dropout(0.5))\n",
    "        self.blk.add(nn.Dense(classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.blk(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(64, kernel_size=11, strides=4,\n",
    "                            padding=5, activation='relu', in_channels=3,layout=\"NHWC\"))\n",
    "net.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "net.add(nn.Conv2D(256, kernel_size=5, padding=2,\n",
    "                            activation='relu',layout=\"NHWC\"))\n",
    "net.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "net.add(nn.Conv2D(384, kernel_size=3, padding=1,\n",
    "                            activation='relu', layout=\"NHWC\"))\n",
    "net.add(nn.Conv2D(256, kernel_size=3, padding=1,\n",
    "                            activation='relu', layout=\"NHWC\"))\n",
    "net.add(nn.Conv2D(256, kernel_size=3, padding=1,\n",
    "                            activation='relu', layout=\"NHWC\"))\n",
    "net.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "net.add(nn.Flatten())\n",
    "net.add(nn.Dense(4096, activation='relu'))\n",
    "net.add(nn.Dropout(0.5))\n",
    "net.add(nn.Dense(4096, activation='relu'))\n",
    "net.add(nn.Dropout(0.5))\n",
    "net.add(nn.Dense(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = gluon.model_zoo.vision.alexnet(pretrained=True)\n",
    "net.initialize(mx.init.Uniform(scale=1))\n",
    "optim = optimizer.Adam(learning_rate=config['learning_rate'])\n",
    "trainer = gluon.Trainer(net.collect_params(), optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = net(mx.nd.zeros((1, 32, 32, 3)))\n",
    "try:\n",
    "    x = x.asnumpy()\n",
    "except:\n",
    "    x = x.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  2.98476573e-43,\n",
       "         0.00000000e+00, -1.02578287e+34,  4.58210585e-41,\n",
       "         1.34524653e-43,  0.00000000e+00,  5.88545355e-44,\n",
       "         0.00000000e+00,  2.67226686e-35,  3.01808660e-29,\n",
       "         1.16621059e-34,  6.91455370e-18, -2.12702664e+38,\n",
       "         3.02888693e-20,  4.50236107e-31,  1.32706333e-16,\n",
       "        -2.00708844e+38,  3.68880274e-14, -1.94062501e+38,\n",
       "         7.71586367e-15, -2.98139341e+09,  2.36474542e+29,\n",
       "         1.00349891e-04,  4.58252624e-41,  1.00349891e-04,\n",
       "         4.58252624e-41, -2.22152009e-14,  9.40667067e-31,\n",
       "        -2.88336968e+29,  4.58238611e-41, -2.88336968e+29,\n",
       "         4.58238611e-41,  1.40129846e-42,  0.00000000e+00,\n",
       "        -5.08326106e+29,  4.58238611e-41, -5.08326106e+29,\n",
       "         4.58238611e-41,  0.00000000e+00,  0.00000000e+00,\n",
       "         7.74249109e-10,  4.58252624e-41,  7.74249109e-10,\n",
       "         4.58252624e-41, -2.43166517e-19,  5.63215725e-02,\n",
       "        -5.87240914e+16,  4.58238611e-41, -5.87240914e+16,\n",
       "         4.58238611e-41,  6.82930984e+01,  8.85712568e+10,\n",
       "         7.88538124e-10,  4.58252624e-41,  7.88538124e-10,\n",
       "         4.58252624e-41,  8.96831017e-44,  0.00000000e+00,\n",
       "         1.04531729e-31,  1.40129846e-45,  1.04531729e-31,\n",
       "         1.40129846e-45,  1.54142831e-44,  0.00000000e+00,\n",
       "         1.04511792e-31,  1.40129846e-45,  1.04511792e-31,\n",
       "         1.40129846e-45,  5.60519386e-45,  0.00000000e+00,\n",
       "         1.04509159e-31,  1.40129846e-45,  1.04509159e-31,\n",
       "         1.40129846e-45,  7.00649232e-45,  0.00000000e+00,\n",
       "         1.04509535e-31,  1.40129846e-45,  1.04509535e-31,\n",
       "         1.40129846e-45,  4.61076208e+20,  1.89959682e+25,\n",
       "         2.41112759e+30,  4.58210585e-41,  2.41112759e+30,\n",
       "         4.58210585e-41,  4.20389539e-45,  0.00000000e+00,\n",
       "         1.04508783e-31,  1.40129846e-45,  1.04508783e-31,\n",
       "         1.40129846e-45,  2.68216976e+08,  4.10559189e+28,\n",
       "         3.01918592e+15,  4.58238611e-41,  3.01918592e+15,\n",
       "         4.58238611e-41, -3.87778269e-38,  3.87756613e+24,\n",
       "         1.18025493e+30,  4.58210585e-41,  1.18025493e+30,\n",
       "         4.58210585e-41,  3.27044403e-12, -9.12234979e+19,\n",
       "         6.30545401e-06,  4.58252624e-41,  6.30545401e-06,\n",
       "         4.58252624e-41, -5.38089375e+05, -2.50617657e-02,\n",
       "         7.70511654e-10,  4.58252624e-41,  7.70511654e-10,\n",
       "         4.58252624e-41,  3.17180734e+13,  9.55653963e-19,\n",
       "         5.26043550e-07,  4.58252624e-41,  5.26043550e-07,\n",
       "         4.58252624e-41, -8.04016411e-01,  2.51902420e+02,\n",
       "         9.57532029e-06,  4.58252624e-41,  9.57532029e-06,\n",
       "         4.58252624e-41,  9.52200160e+07, -7.23984056e+10,\n",
       "         9.62367048e-05,  4.58252624e-41,  9.62367048e-05,\n",
       "         4.58252624e-41, -5.22110980e-27,  2.77980188e+05,\n",
       "         9.98092219e-07,  4.58252624e-41,  9.98092219e-07,\n",
       "         4.58252624e-41,  2.80259693e-45,  0.00000000e+00,\n",
       "         1.04508407e-31,  1.40129846e-45,  1.04508407e-31,\n",
       "         1.40129846e-45,  1.40129846e-45,  0.00000000e+00,\n",
       "         1.04508031e-31,  1.40129846e-45,  1.04508031e-31,\n",
       "         1.40129846e-45, -9.11480062e+11, -1.67547727e-20,\n",
       "        -5.87326126e+16,  4.58238611e-41, -5.87326126e+16,\n",
       "         4.58238611e-41, -6.49473444e-03,  1.14334179e-26,\n",
       "         4.46030026e-06,  4.58252624e-41,  4.46030026e-06,\n",
       "         4.58252624e-41,  3.58732407e-43,  0.00000000e+00,\n",
       "         1.04603951e-31,  1.40129846e-45,  1.04603951e-31,\n",
       "         1.40129846e-45, -6.42374894e+37,  2.93938510e-22,\n",
       "        -5.87293141e+16,  4.58238611e-41, -5.87293141e+16,\n",
       "         4.58238611e-41,  5.38098610e-43,  0.00000000e+00,\n",
       "        -5.08224557e+29,  4.58238611e-41, -5.08224557e+29,\n",
       "         4.58238611e-41,  5.73971851e-42,  0.00000000e+00,\n",
       "        -5.08243899e+29,  4.58238611e-41, -5.08243899e+29,\n",
       "         4.58238611e-41, -2.75771136e+09,  7.75773009e-23,\n",
       "        -3.36185829e+31,  4.58238611e-41, -3.36185829e+31,\n",
       "         4.58238611e-41,  1.12258748e-03,  8.29136127e-07,\n",
       "         1.17239208e+30,  4.58210585e-41,  1.17239208e+30,\n",
       "         4.58210585e-41,  3.30810755e+33,  1.10060304e-30,\n",
       "        -5.87284895e+16,  4.58238611e-41, -5.87284895e+16,\n",
       "         4.58238611e-41, -5.71490465e+18,  1.52971136e+25,\n",
       "        -5.87378353e+16,  4.58238611e-41, -5.87378353e+16,\n",
       "         4.58238611e-41, -2.36264463e+12,  1.68460281e+37,\n",
       "         1.18026944e+30,  4.58210585e-41,  1.18026944e+30,\n",
       "         4.58210585e-41,  1.67135372e-31, -2.70965525e-17,\n",
       "         1.17321415e+30,  4.58210585e-41,  1.17321415e+30,\n",
       "         4.58210585e-41, -1.27691076e-12, -1.41877266e+04,\n",
       "        -5.87345368e+16,  4.58238611e-41, -5.87345368e+16,\n",
       "         4.58238611e-41, -3.34885529e+02,  2.60144746e-28,\n",
       "        -2.92803647e+29,  4.58238611e-41, -2.92803647e+29,\n",
       "         4.58238611e-41, -9.90355728e-29,  1.97263936e+08,\n",
       "        -2.93327414e+29,  4.58238611e-41, -2.93327414e+29,\n",
       "         4.58238611e-41,  3.03102528e+35, -5.24357403e-34,\n",
       "         1.18772610e+30,  4.58210585e-41,  1.18772610e+30,\n",
       "         4.58210585e-41, -3.76517451e+32, -2.83309759e+18,\n",
       "         1.18760520e+30,  4.58210585e-41,  1.18760520e+30,\n",
       "         4.58210585e-41,  4.21606386e+27, -3.72563868e-27,\n",
       "        -5.87265653e+16,  4.58238611e-41, -5.87265653e+16,\n",
       "         4.58238611e-41,  3.26070839e-16, -4.09404000e+06,\n",
       "        -2.92810296e+29,  4.58238611e-41, -2.92810296e+29,\n",
       "         4.58238611e-41,  1.42714640e+35,  7.63532597e+25,\n",
       "        -2.93328925e+29,  4.58238611e-41, -2.93328925e+29,\n",
       "         4.58238611e-41,  5.84709596e-07,  4.58252624e-41,\n",
       "         9.61240148e-05,  4.58252624e-41, -5.08243899e+29,\n",
       "         4.58238611e-41,  9.57532029e-06,  4.58252624e-41,\n",
       "        -7.43904041e+29,  4.58238611e-41,  7.81759546e-10,\n",
       "         4.58252624e-41,  1.14726390e-06,  4.58252624e-41,\n",
       "         7.68856090e-10,  4.58252624e-41,  5.84709596e-07,\n",
       "         4.58252624e-41,  6.30589057e-06,  4.58252624e-41,\n",
       "        -5.59453331e+19,  4.58210585e-41,  7.81759546e-10,\n",
       "         4.58252624e-41,  1.14726390e-06,  4.58252624e-41,\n",
       "         7.68856090e-10,  4.58252624e-41,  5.84709596e-07,\n",
       "         4.58252624e-41,  9.61240148e-05,  4.58252624e-41,\n",
       "        -5.08310390e+29,  4.58238611e-41,  9.57532029e-06,\n",
       "         4.58252624e-41,  1.18137077e+30,  4.58210585e-41,\n",
       "         7.81759546e-10,  4.58252624e-41,  1.14726390e-06,\n",
       "         4.58252624e-41,  7.68856090e-10,  4.58252624e-41,\n",
       "         5.84709596e-07,  4.58252624e-41,  6.30589057e-06,\n",
       "         4.58252624e-41,  1.16235796e+10,  4.58224598e-41,\n",
       "         7.81759546e-10,  4.58252624e-41,  8.75739659e-09,\n",
       "         4.58252624e-41,  5.84709596e-07,  4.58252624e-41,\n",
       "         9.61240148e-05,  4.58252624e-41,  1.34157716e-08,\n",
       "         4.58252624e-41,  9.56583535e-05,  4.58252624e-41,\n",
       "         7.81759546e-10,  4.58252624e-41,  1.31725955e-08,\n",
       "         4.58252624e-41,  7.85230547e-10,  4.58252624e-41,\n",
       "         6.36674270e+16,  2.79423802e+32,  8.17136494e+20,\n",
       "         4.48037143e+24,  1.10462535e+27,  8.92617813e-10,\n",
       "         6.36674270e+16,  2.79423802e+32,  8.17136494e+20,\n",
       "         4.35833094e-08,  1.94135064e+17,  2.56389154e-09,\n",
       "         3.41123980e+27,  6.41952047e-10,  7.98112743e-10,\n",
       "         3.48557723e+27,  6.41952047e-10,  7.98112743e-10,\n",
       "         8.92618257e-10,  6.36674270e+16,  1.66922064e-07,\n",
       "         8.92618257e-10,  6.36674270e+16,  2.79423802e+32,\n",
       "         8.17136494e+20,  2.67050948e+17,  8.92618313e-10,\n",
       "         6.36674270e+16,  1.04326299e-08,  1.35632559e-19,\n",
       "         6.78776928e-07,  6.41952047e-10,  7.98112743e-10,\n",
       "         1.35632559e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         2.79042207e+32,  8.17136494e+20,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.01958901e-31,  1.40129846e-45,\n",
       "         2.87406315e-42,  0.00000000e+00,  7.02947816e+28,\n",
       "         6.19491795e-04,  8.84368737e-18,  6.97299896e+22,\n",
       "         7.26701365e+31,  1.75892947e+22,  1.28807812e+04,\n",
       "         6.45091147e-10,  1.70314036e+28,  6.08375196e+22,\n",
       "         2.68370791e+17,  2.72537267e+20,  1.00281858e+01,\n",
       "         1.04184909e+09,  1.72497578e+05,  1.83140670e+25,\n",
       "         7.31187237e+28,  6.46284025e-04,  1.35890420e-19,\n",
       "         2.72609065e+17,  1.82800989e+17,  6.97299986e+22,\n",
       "         7.26701365e+31,  1.76665405e+22,  1.89394541e+23,\n",
       "         2.01115550e-19,  1.94316151e-19,  2.72396288e+09,\n",
       "         3.25322162e+33,  1.78868262e+22,  1.83192771e+25,\n",
       "         3.96583981e-11,  1.37524334e-19,  1.98531611e+29,\n",
       "         4.54450720e+30,  2.68369588e+17,  1.35632572e-19,\n",
       "         4.46278351e+30,  7.27084014e+31,  2.74096790e+17,\n",
       "         1.35632572e-19,  9.84393123e-12,  9.84394250e-12,\n",
       "         1.94979369e+17,  1.35632572e-19,  2.72535894e+20,\n",
       "         1.81789790e+31,  1.21064137e+25,  1.46074900e-19,\n",
       "         2.65628569e+20,  2.07034893e-19,  6.40969111e-10,\n",
       "         1.35890420e-19,  1.35631564e-19,  2.61295099e+32,\n",
       "         4.54342763e+30,  1.95185260e-19,  1.78598806e+31,\n",
       "         2.06164673e-19,  2.05350560e-19,  1.94316151e-19,\n",
       "         3.02625244e+29,  7.75912336e+26,  4.54520354e+30,\n",
       "         2.01898838e-19,  1.80285272e+17,  1.82800989e+17,\n",
       "         2.01898683e-19,  1.18151756e+22,  1.15580365e+19,\n",
       "         1.80138716e+25,  1.23996848e-14,  2.79087474e+23,\n",
       "         1.09831235e+27,  7.18539638e+22,  6.44795495e-10,\n",
       "         1.45849106e-19,  4.76970684e+33,  1.83371041e+31,\n",
       "         1.70392534e+28,  1.35631564e-19,  1.35631564e-19,\n",
       "         7.09709070e+22,  9.34054723e+26,  6.09392739e+22,\n",
       "         1.26902636e+31,  5.11642764e-14,  1.68774957e+25,\n",
       "         1.76117288e+19,  1.51130397e-13,  4.46582366e+30,\n",
       "         1.90784629e+17,  1.35632572e-19,  1.35631564e-19,\n",
       "         7.39881171e+31,  7.17583028e+22,  1.34935530e+28,\n",
       "         1.65319765e+19,  2.96348576e+29,  6.45285763e-04,\n",
       "         1.35890420e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         7.17579786e+22,  2.05895280e+23,  3.09789021e+32,\n",
       "         2.06164661e-19,  1.84241015e+28,  1.14961009e+21,\n",
       "         9.81021622e+11,  7.24419718e+22,  2.69155063e+20,\n",
       "         4.75681724e+30,  1.89356559e+34,  3.71154828e-14,\n",
       "         1.35890420e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.86722740e+25,  1.27088327e+31,  5.23922190e-11,\n",
       "         7.14308714e+31,  1.81786720e+31,  4.36045789e+27,\n",
       "         4.48943271e+21,  1.27364338e-14,  1.70392534e+28,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  2.79087474e+23,  2.64479201e+20,\n",
       "         7.15612073e+22,  1.66154577e+22,  1.84265654e+28,\n",
       "         1.85120332e+28,  1.08911276e-14,  1.45862418e-19,\n",
       "         1.87544948e+28,  1.77014267e+31,  5.60249425e-02,\n",
       "         1.45852428e-19,  1.83193728e+25,  5.94228655e-02,\n",
       "         1.70350351e+28,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.68515150e+22,  5.65017797e-02,  1.84666532e+20,\n",
       "         1.18375564e+33,  7.22507008e+28,  3.31252868e+30,\n",
       "         3.40593409e-15,  1.80372252e+28,  2.67925317e+20,\n",
       "         1.10946201e+27,  2.54715411e-12,  7.71795433e+28,\n",
       "         2.13307266e+17,  2.20237903e+14,  3.60512503e-14,\n",
       "         2.01898774e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.26864482e+31,  5.23922190e-11,\n",
       "         7.14308714e+31,  1.81786720e+31,  1.68514407e+22,\n",
       "         5.42127732e-11,  1.66685051e+10,  1.37623450e-08,\n",
       "         7.43250805e+28,  1.77014388e+31,  5.60249425e-02,\n",
       "         1.26901850e+31,  1.72253543e+22,  1.10274856e-08,\n",
       "         2.76846050e+20,  1.80578430e+28,  3.93551531e-14,\n",
       "         2.01898774e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.26864482e+31,  5.23922190e-11,\n",
       "         7.14308714e+31,  1.81786720e+31,  1.68514407e+22,\n",
       "         5.42127732e-11,  1.20900714e+33,  9.79439285e-09,\n",
       "         1.45869023e-19,  1.87544948e+28,  1.77014267e+31,\n",
       "         5.60249425e-02,  1.98284178e+29,  1.72568196e+25,\n",
       "         1.10247651e-08,  2.01898813e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.84612119e+20,  1.18375564e+33,  7.22507008e+28,\n",
       "         3.31252868e+30,  3.40593409e-15,  7.31537987e+34,\n",
       "         5.96823059e-02,  2.11081438e+05,  2.98512092e-18,\n",
       "         1.70341154e+28,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  2.79087474e+23,\n",
       "         2.64479201e+20,  7.15612073e+22,  1.66154577e+22,\n",
       "         1.84265654e+28,  1.82786279e+34,  1.15783572e+27,\n",
       "         2.08303699e+29,  1.70369580e+19,  7.39085510e+22,\n",
       "         1.45859200e-19,  1.83193728e+25,  5.94228655e-02,\n",
       "         1.98284122e+29,  1.72568196e+25,  2.75619128e-09,\n",
       "         1.70341154e+28,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  2.79087474e+23,\n",
       "         2.64479201e+20,  7.15612073e+22,  1.66154577e+22,\n",
       "         1.84265654e+28,  1.85120332e+28,  1.08911276e-14,\n",
       "         2.56107353e-12,  4.54410070e+30,  1.70341421e+19,\n",
       "         7.39085510e+22,  1.45859200e-19,  1.68515150e+22,\n",
       "         5.65017797e-02,  1.70350316e+28,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.84654502e+25,  1.84648841e+25,\n",
       "         2.62888851e-15,  2.99667875e+32,  7.74546539e+26,\n",
       "         3.03569533e+32,  2.98480928e-18,  2.15282440e+02,\n",
       "         3.75553402e-14,  1.35890420e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  7.17579786e+22,\n",
       "         2.05895280e+23,  3.09789021e+32,  5.53419047e-11,\n",
       "         1.26783087e-14,  1.74431366e+02,  1.43441943e-08,\n",
       "         6.63687615e-07,  1.93636911e+26,  7.03770893e+22,\n",
       "         1.83887245e+25,  4.40972840e-08,  2.76846050e+20,\n",
       "         1.80578430e+28,  2.51872980e-12,  1.35890420e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  4.15283227e+21,  2.84093609e+20,\n",
       "         1.85236006e+28,  7.14710317e+22,  2.37973096e-12,\n",
       "         7.31537393e+34,  5.96823059e-02,  2.11081438e+05,\n",
       "         2.98512092e-18,  1.70341154e+28,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         2.79087474e+23,  2.64479201e+20,  7.15612073e+22,\n",
       "         1.66154577e+22,  1.84265654e+28,  1.85120332e+28,\n",
       "         1.08911276e-14,  2.58932849e-12,  4.54410070e+30,\n",
       "         1.70341421e+19,  7.39085510e+22,  1.45859200e-19,\n",
       "         1.68515150e+22,  5.65017797e-02,  1.70350316e+28,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.84654502e+25,\n",
       "         1.84648841e+25,  2.62888851e-15,  2.99667875e+32,\n",
       "         7.74546539e+26,  3.03569533e+32,  2.98480928e-18,\n",
       "         2.15282440e+02,  3.75553402e-14,  1.35890420e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         7.17579786e+22,  2.05895280e+23,  3.09789021e+32,\n",
       "         5.53419047e-11,  1.26783087e-14,  1.82904544e+08,\n",
       "         6.45184112e+28,  7.13694275e+02,  7.41025059e+28,\n",
       "         1.83887245e+25,  4.40972840e-08,  7.70496008e+31,\n",
       "         6.74152925e+22,  2.53294326e-12,  1.66343875e+22,\n",
       "         1.12586734e+24,  3.75682456e-14,  1.35890420e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         7.17579786e+22,  2.05895280e+23,  3.09789021e+32,\n",
       "         5.53419047e-11,  1.26783087e-14,  1.11636074e+04,\n",
       "         7.74472891e+31,  3.73992456e-14,  2.01898774e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.26864482e+31,  5.23922190e-11,  7.14308714e+31,\n",
       "         1.81786720e+31,  1.68514407e+22,  5.42127732e-11,\n",
       "         1.88876429e+31,  6.55410226e-10,  1.45869075e-19,\n",
       "         1.84654502e+25,  1.84648841e+25,  2.62888851e-15,\n",
       "         2.99667875e+32,  1.90458074e+17,  1.35632572e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.10955070e+27,  6.79375119e+22,  4.86172934e+30,\n",
       "         2.01128033e+20,  1.30287116e+28,  3.88577229e+30,\n",
       "         3.03525238e+32,  4.00536965e-11,  1.90458315e+17,\n",
       "         1.35632572e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.10955070e+27,  6.79375119e+22,\n",
       "         4.86172934e+30,  2.01128033e+20,  1.30287116e+28,\n",
       "         5.79025192e+22,  1.27370835e-14,  2.75952061e-06,\n",
       "         4.15283564e+21,  2.84093609e+20,  1.85236006e+28,\n",
       "         7.14710317e+22,  3.71832963e-14,  2.01898774e-19,\n",
       "         1.35631564e-19,  1.35631564e-19,  1.35631564e-19,\n",
       "         1.26864482e+31,  5.23922190e-11,  7.14308714e+31,\n",
       "         1.81786720e+31,  1.68514407e+22,  5.42127732e-11,\n",
       "         2.96420224e+29,  1.35701853e-14,  4.02301348e-14,\n",
       "         2.68369502e+17,  1.35632572e-19,  1.35631564e-19,\n",
       "         1.35631564e-19,  1.10955070e+27,  3.03198247e+32,\n",
       "         7.77828095e+31,  1.23978743e+28,  5.79025192e+22,\n",
       "         1.27370835e-14,  1.78598806e+31,  5.40448322e-14,\n",
       "         1.70550296e+28,  1.35631564e-19,  1.95153051e-19,\n",
       "         4.48578454e+30,  2.63734992e+23,  2.85286975e+20,\n",
       "         1.33414176e+31,  3.27451369e-12,  1.45921691e-19,\n",
       "         2.09599764e+17,  1.35632572e-19,  1.35631564e-19,\n",
       "         3.91770601e-02,  1.10955070e+27,  6.79375119e+22,\n",
       "         4.86172934e+30,  1.36663492e+34,  2.01898774e-19,\n",
       "         1.35631564e-19,  1.29909230e+34,  1.26954233e+31,\n",
       "         5.23922190e-11,  3.02625244e+29,  1.36666860e+34,\n",
       "         2.01898774e-19,  1.35631564e-19,  3.17161205e+30,\n",
       "         4.86173054e+30,  3.36274355e-18,  1.85895167e+34,\n",
       "         7.77666437e+31,  1.71810666e+19,  1.89896214e+28,\n",
       "         1.73351339e-07,  1.14985199e-38,  1.10955129e+27,\n",
       "         1.02510996e+04,  5.50949667e-14,  2.01898994e-19,\n",
       "         1.35631564e-19,  1.29909230e+34,  1.26954233e+31,\n",
       "         5.23922190e-11,  7.14308714e+31,  1.81786720e+31,\n",
       "         1.90805537e+17,  1.35632572e-19,  1.35631564e-19,\n",
       "         3.91770601e-02,  1.10955070e+27,  3.03198247e+32,\n",
       "         7.77828095e+31,  1.90805537e+17,  1.35632572e-19,\n",
       "         1.35631564e-19,  7.27142768e+31,  2.01972548e-19,\n",
       "         1.14918021e-38,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AlexNet and CIFAR100 \n",
    "# Net\n",
    "\n",
    "class AlexNet(HybridBlock):\n",
    "    r\"\"\"AlexNet model from the `\"One weird trick...\" `_ paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classes : int, default 1000\n",
    "        Number of classes for the output layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, classes=1000, **kwargs):\n",
    "        super(AlexNet, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.features = nn.HybridSequential(prefix='')\n",
    "            with self.features.name_scope():\n",
    "                self.features.add(nn.Conv2D(64, kernel_size=11, strides=4,\n",
    "                                            padding=5, activation='relu', in_channels=3,layout=\"NHWC\"))\n",
    "                self.features.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "                self.features.add(nn.Conv2D(256, kernel_size=5, padding=2,\n",
    "                                            activation='relu',layout=\"NHWC\"))\n",
    "                self.features.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "                self.features.add(nn.Conv2D(384, kernel_size=3, padding=1,\n",
    "                                            activation='relu', layout=\"NHWC\"))\n",
    "                self.features.add(nn.Conv2D(256, kernel_size=3, padding=1,\n",
    "                                            activation='relu', layout=\"NHWC\"))\n",
    "                self.features.add(nn.Conv2D(256, kernel_size=3, padding=1,\n",
    "                                            activation='relu', layout=\"NHWC\"))\n",
    "                self.features.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "                self.features.add(nn.Flatten())\n",
    "                self.features.add(nn.Dense(4096, activation='relu'))\n",
    "                self.features.add(nn.Dropout(0.5))\n",
    "                self.features.add(nn.Dense(4096, activation='relu'))\n",
    "                self.features.add(nn.Dropout(0.5))\n",
    "\n",
    "            self.output = nn.Dense(classes)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'transforms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-a85eb7d5e12a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     transforms.Normalize(0, 1)])\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'transforms'"
     ]
    }
   ],
   "source": [
    "def transform(data, label):\n",
    "    data = data.astype('float32')/255\n",
    "    return data, label\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0, 1)])\n",
    "\n",
    "train_dataset = vision.datasets.CIFAR100(train=True, transform=vision.transforms.Compose())\n",
    "valid_dataset = vision.datasets.CIFAR100(train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ctx, val_data, net):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for data, label in val_data:\n",
    "        data = data.as_in_context(ctx[0])\n",
    "        label = label.as_in_context(ctx[0])\n",
    "        output = net(data)\n",
    "        try:\n",
    "            metric.update(label, output)\n",
    "        except:\n",
    "            metric.update(label, output)\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mxnet_objective(config):\n",
    "    net = AlexNet()\n",
    "    #net = gluoncv.model_zoo.get_model('alexnet', classes=1000, pretrained=False)\n",
    "    gpus = mx.test_utils.list_gpus()\n",
    "    ctx = [mx.gpu()] if gpus else [mx.cpu()]\n",
    "    net.initialize(mx.init.Uniform(scale=1), ctx=ctx)\n",
    "    optim = optimizer.Adam(learning_rate=config['learning_rate'])\n",
    "    trainer = gluon.Trainer(net.collect_params(), optim)\n",
    "    \n",
    "    train_data = gluon.data.DataLoader(vision.datasets.CIFAR100(train=True, transform=transform), batch_size=config['batch_size'], shuffle=False)\n",
    "    val_data = gluon.data.DataLoader(vision.datasets.CIFAR100(train=False, transform=transform), batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "    train_metric = mx.metric.Accuracy()\n",
    "    train_history = TrainingHistory(['training-error', 'validation-error'])\n",
    "    \n",
    "#     # Use Accuracy as the evaluation metric.\n",
    "#     metric = mx.metric.Accuracy()\n",
    "    criterion = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    \n",
    "        \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_metric.reset()\n",
    "        train_loss, train_acc, valid_acc = 0., 0., 0.\n",
    "        for data, label in train_data:\n",
    "            # forward + backward\n",
    "            with ag.record():\n",
    "                output = net(data)\n",
    "                loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            # update parameters\n",
    "            trainer.step(config['batch_size'])\n",
    "\n",
    "    name, acc = train_metric.get()\n",
    "    # Evaluate on Validation data\n",
    "    name, val_acc = test(ctx, val_data, net)\n",
    "    print(val_acc)\n",
    "\n",
    "#     # Update history and print metrics\n",
    "#     #train_history.update([1-acc, 1-val_acc])\n",
    "    \n",
    "# #     return (val_acc, net)\n",
    "#     for epoch in range(config['epochs']):\n",
    "#     # training loop (with autograd and trainer steps, etc.)\n",
    "#         cumulative_train_loss = mx.nd.zeros(1)\n",
    "#         training_samples = 0\n",
    "#         for batch_idx, (data, label) in enumerate(train_data):\n",
    "#             with ag.record():\n",
    "#                 output = net(data)\n",
    "#                 loss = criterion(output, label)\n",
    "#             loss.backward()\n",
    "#             trainer.step(data.shape[0])\n",
    "#             cumulative_train_loss += loss.sum()\n",
    "#             training_samples += data.shape[0]\n",
    "#         try:\n",
    "#             train_loss = cumulative_train_loss.asscalar()/training_samples\n",
    "#         except:\n",
    "#             train_loss = cumulative_train_loss.asscalar()/training_samples\n",
    "#         print(cumulative_train_loss)\n",
    "\n",
    "#     # validation loop\n",
    "#     cumulative_valid_loss = mx.nd.zeros(1, ctx)\n",
    "#     valid_samples = 0\n",
    "#     for batch_idx, (data, label) in enumerate(val_data):\n",
    "#         data = data.as_in_context(ctx).reshape((-1, 1024)) # 28*28=784\n",
    "#         label = label.as_in_context(ctx)\n",
    "#         output = net(data)\n",
    "#         loss = criterion(output, label)\n",
    "#         cumulative_valid_loss += loss.sum()\n",
    "#         valid_samples += data.shape[0]\n",
    "#     valid_loss = cumulative_valid_loss.asscalar()/valid_samples\n",
    "\n",
    "#     print(\"Epoch {}, training loss: {:.2f}, validation loss: {:.2f}\".format(epoch, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'learning_rate':.001, 'dropout':0.5, 'batch_size':100, 'epochs':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "mxnet_objective(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(output, label):\n",
    "    # output: (batch, num_output) float32 ndarray\n",
    "    # label: (batch, ) int32 ndarray\n",
    "    return (output.argmax(axis=1) ==\n",
    "            label.astype('float32')).mean().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mxnet_objective(config):\n",
    "    net = AlexNet()\n",
    "    #net = gluoncv.model_zoo.get_model('alexnet', classes=1000, pretrained=False)\n",
    "#     gpus = mx.test_utils.list_gpus()\n",
    "#     ctx = [mx.gpu()] if gpus else [mx.cpu()]\n",
    "#     net.initialize(mx.init.Uniform(scale=1), ctx=ctx)\n",
    "    net.initialize(mx.init.Uniform(scale=1))\n",
    "    optim = optimizer.Adam(learning_rate=config['learning_rate'])\n",
    "    trainer = gluon.Trainer(net.collect_params(), optim)\n",
    "    \n",
    "    train_data = gluon.data.DataLoader(vision.datasets.CIFAR100(train=True, transform=transform), batch_size=config['batch_size'], shuffle=False)\n",
    "    val_data = gluon.data.DataLoader(vision.datasets.CIFAR100(train=False, transform=transform), batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "#     train_metric = mx.metric.Accuracy()\n",
    "#     train_history = TrainingHistory(['training-error', 'validation-error'])\n",
    "    \n",
    "#     # Use Accuracy as the evaluation metric.\n",
    "#     metric = mx.metric.Accuracy()\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    \n",
    "        \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc, valid_acc = 0., 0., 0.\n",
    "        tic = time.time()\n",
    "        for data, label in train_data:\n",
    "            # forward + backward\n",
    "            with ag.record():\n",
    "                output = net(data)\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            # update parameters\n",
    "            trainer.step(config['batch_size'])\n",
    "            # calculate training metrics\n",
    "            train_loss += loss.mean().asscalar()\n",
    "            train_acc += acc(output, label)\n",
    "    # calculate validation accuracy\n",
    "    for data, label in valid_data:\n",
    "        valid_acc += acc(net(data), label)\n",
    "    print(\"Epoch %d: loss %.3f, train acc %.3f, test acc %.3f, in %.1f sec\" % (\n",
    "            epoch, train_loss/len(train_data), train_acc/len(train_data),\n",
    "            valid_acc/len(valid_data), time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "MXNetError: could not create a descriptor for a dilated convolution forward propagation primitive",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-09da03b4df2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmxnet_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-332-1fa42be9fcd2>\u001b[0m in \u001b[0;36mmxnet_objective\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# calculate training metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# calculate validation accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/resiliency/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/resiliency/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         \"\"\"\n\u001b[1;32m   2562\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m         check_call(_LIB.MXNDArraySyncCopyToCPU(\n\u001b[0m\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/resiliency/lib/python3.8/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: MXNetError: could not create a descriptor for a dilated convolution forward propagation primitive"
     ]
    }
   ],
   "source": [
    "mxnet_objective(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AlexNet()\n",
    "#net = gluoncv.model_zoo.get_model('alexnet', classes=1000, pretrained=False)\n",
    "#     gpus = mx.test_utils.list_gpus()\n",
    "#     ctx = [mx.gpu()] if gpus else [mx.cpu()]\n",
    "#     net.initialize(mx.init.Uniform(scale=1), ctx=ctx)\n",
    "net.initialize(mx.init.Uniform(scale=1))\n",
    "optim = optimizer.Adam(learning_rate=config['learning_rate'])\n",
    "trainer = gluon.Trainer(net.collect_params(), optim)\n",
    "\n",
    "train_data = gluon.data.DataLoader(vision.datasets.CIFAR100(train=True, transform=transform), batch_size=config['batch_size'], shuffle=False)\n",
    "val_data = gluon.data.DataLoader(vision.datasets.CIFAR100(train=False, transform=transform), batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "#     train_metric = mx.metric.Accuracy()\n",
    "#     train_history = TrainingHistory(['training-error', 'validation-error'])\n",
    "\n",
    "#     # Use Accuracy as the evaluation metric.\n",
    "#     metric = mx.metric.Accuracy()\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "ctx = mx.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "MXNetError: could not create a descriptor for a dilated convolution forward propagation primitive",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-316-11855ad2f285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# accumulating loss of current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcum_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcum_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# len(train_loader) gives number of batches, so you are dividing all accumulated loss by num of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After epoch {}: Loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/resiliency/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/resiliency/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         \"\"\"\n\u001b[1;32m   2562\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m         check_call(_LIB.MXNDArraySyncCopyToCPU(\n\u001b[0m\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/resiliency/lib/python3.8/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: MXNetError: could not create a descriptor for a dilated convolution forward propagation primitive"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    cum_loss = 0.0\n",
    "    for inputs, labels in train_data:\n",
    "        inputs = inputs.as_in_context(ctx)\n",
    "        # ctx can be mx.gpu() if gpu available otherwise mx.cpu()\n",
    "        labels = labels.as_in_context(ctx)\n",
    "        # ctx can be mx.gpu() if gpu available otherwise mx.cpu()\n",
    "        with ag.record():\n",
    "            outputs = net(inputs)\n",
    "            loss = softmax_cross_entropy(outputs, labels)\n",
    "            # here you are computing the loss\n",
    "        loss.backward()\n",
    "        # here you are differentiating your loss with respect to all your model parameters.\n",
    "        trainer.step(batch_size=inputs.shape[0])\n",
    "        # running trainer\n",
    "        cum_loss += loss.mean()\n",
    "        # accumulating loss of current batch\n",
    "    cum_loss = cum_loss.as_in_context(ctx)\n",
    "    epoch_loss = cum_loss.asscalar()/len(train_loader) \n",
    "    # len(train_loader) gives number of batches, so you are dividing all accumulated loss by num of batches\n",
    "    print('After epoch {}: Loss: {}'.format(epoch + 1, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
